{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy.ndimage.filters import convolve\n",
    "try:\n",
    "    from astropy.io import fits\n",
    "except ImportError:\n",
    "    import pyfits as fits\n",
    "import matplotlib.pyplot as plt\n",
    "import pdb\n",
    "\n",
    "def pad_psf(psf, spectrum):\n",
    "    out_psf = np.zeros( spectrum.shape )\n",
    "    start = len(spectrum)/2 - len(psf)/2\n",
    "    end = start + len(psf)\n",
    "    out_psf[start:end] = psf\n",
    "\n",
    "    return out_psf\n",
    "\n",
    "def rl_fft(raw_image, psf, niter, k=1, con_var=None):\n",
    "    calc_chisq = lambda a, b, c, d: np.sum((a - b)**2 / (a + c)**2 / (d-1))\n",
    "    \n",
    "    conversion =  raw_image.mean() / 10\n",
    "    raw_image /= conversion\n",
    "    \n",
    "    lucy = np.ones(raw_image.shape)\n",
    "    ratio = k * np.ones(raw_image.shape)\n",
    "    fft_psf = np.fft.fft(psf)\n",
    "    \n",
    "    con_var = sample_noise(raw_image)\n",
    "    print (\"using: \", con_var)\n",
    "\n",
    "    norm = np.fft.ifft(np.fft.fft(ratio) * np.conj(fft_psf))\n",
    "    fft_conv = fft_psf * np.fft.fft(lucy)\n",
    "    lucy_conv = np.fft.ifft(fft_conv)\n",
    "\n",
    "    chisq = calc_chisq(lucy_conv, raw_image, con_var, raw_image.size)\n",
    "    print (\"initial Chisq: {}\".format(chisq))\n",
    "\n",
    "    for iteration in range(niter):\n",
    "        ratio = k * (raw_image + con_var) / (lucy_conv + con_var)\n",
    "        fft_srat = np.fft.fft(ratio) * np.conj(fft_psf)\n",
    "\n",
    "        lucy *= np.fft.ifft(fft_srat) / norm\n",
    "        print (lucy.max(), lucy.mean(), lucy.min())\n",
    "        fft_conv = fft_psf * np.fft.fft(lucy)\n",
    "        lucy_conv = np.fft.ifft(fft_conv)\n",
    "        size = lucy.size\n",
    "        chisq = calc_chisq(lucy_conv, raw_image, con_var, raw_image.size)\n",
    "        print (\"Iteration {} Chisq: {}\".format(iteration, chisq))\n",
    "    lucy = lucy[range(size/2,size)+range(0,size/2)]\n",
    "    return lucy * conversion\n",
    "\n",
    "def richardson_lucy(image, psf, iterations=50, clip=True):\n",
    "    #Richarson lucy method to calculate the deconvolution of two matrix\n",
    "    #image represents the input image which is blurred and is needed to be deconvolved with the obtained filter\n",
    "    #Iterations are necessary to get a close approximation\n",
    "    direct_time = np.prod(image.shape + psf.shape)\n",
    "    fft_time =  np.sum([n*np.log(n) for n in image.shape + psf.shape])\n",
    "    time_ratio = 40.032 * fft_time / direct_time\n",
    "    if time_ratio <= 1 or len(image.shape) > 2:      # Calculate the time required to calculate convolution \n",
    "        convolve_method = fftconvolve                # and selects more faster option  \n",
    "    else:\n",
    "        convolve_method = convolve\n",
    "    image = image.astype(np.float)\n",
    "    psf = psf.astype(np.float)\n",
    "    im_deconv = 0.5 * np.ones(image.shape)           # Defining the deconvolved matrix which would be written over \n",
    "    psf_mirror = psf[::-1, ::-1]\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        relative_blur = image / convolve_method(im_deconv, psf, 'same') #\n",
    "        relative_blur[np.isnan(relative_blur)] = 0       # to prevent NaN from propogating throughout convulated matrix\n",
    "        relative_blur[np.isnan(relative_blur)] = 0       # to prevent NaN from propogating throughout convulated matrix\n",
    "        im_deconv *= convolve_method(relative_blur, psf_mirror, 'same')\n",
    "\n",
    "    if clip:\n",
    "        im_deconv[im_deconv > 1] = 1\n",
    "        im_deconv[im_deconv < -1] = -1\n",
    "    return im_deconv\n",
    "\n",
    "def sample_noise( spectrum ):\n",
    "    samples = [spectrum[start:start+300].std() for start in range(0, len(spectrum), 300) ]\n",
    "\n",
    "    return np.median( samples )\n",
    "\n",
    "def rl_damped(raw, psf, niter=2, damped=True, N=3, T=None, multiplier=1):\n",
    "\n",
    "    conversion = raw.mean() / 10\n",
    "    raw /= conversion\n",
    "    lucy = np.ones(raw.shape) * raw.mean()\n",
    "    for i in xrange(niter):\n",
    "        if damped:\n",
    "            print (\"dampening\")\n",
    "            lucy_temp = convolve( lucy, psf, mode='mirror')\n",
    "            ratio = dampen(lucy_temp, raw, N, T, multiplier)\n",
    "        else:\n",
    "            ratio = raw / convolve(lucy, psf, mode='mirror')\n",
    "\n",
    "        ratio[ np.isnan(ratio) ] = 0\n",
    "\n",
    "        top = convolve( ratio, psf, mode='mirror')\n",
    "        top[ np.isnan(top) ] = 0\n",
    "\n",
    "        lucy = lucy * (top / psf.sum())\n",
    "        print ('iteration', i, lucy.mean(), raw.mean())\n",
    "\n",
    "    return lucy * conversion\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
